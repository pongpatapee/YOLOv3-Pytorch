{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from dataset import CocoDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()]) \n",
    "train_dataset = CocoDetection('coco128/train2017', 'coco128/annotations/instances_train2017.json', img_size=416, transform=transform)\n",
    "test_dataset = CocoDetection('coco128/val2017', 'coco128/annotations/instances_val2017.json', img_size=416, transform=transform)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "imgs, annotations = next(iter(train_loader))\n",
    "image = imgs[0].numpy().transpose(1, 2, 0)\n",
    "annotation = annotations[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "tensor([320.0000, 240.3501, 640.0000, 477.6499])\n",
      "[0.0, 2.3500799999999913, 640.0, 477.64992]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def draw_bboxes(image, annotation):\n",
    "    num_obj = len(annotation)\n",
    "\n",
    "    for i in range(num_obj):\n",
    "        x = int(annotation[i]['bbox'][0])\n",
    "        y = int(annotation[i]['bbox'][1])\n",
    "        w = int(annotation[i]['bbox'][2])\n",
    "        h = int(annotation[i]['bbox'][3])\n",
    "\n",
    "        centerx = int(annotation[i]['yolo_bbox'][0])\n",
    "        centery = int(annotation[i]['yolo_bbox'][1])\n",
    "\n",
    "        image = cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        # draw circle at center of bbox to confirm yolo_bbox is correct\n",
    "        image = cv2.circle(image, (centerx, centery), 1, (0, 255, 0), 2)\n",
    "\n",
    "    return image\n",
    "\n",
    "print(image.shape)\n",
    "print(annotation[0]['yolo_bbox'])\n",
    "print(annotation[0]['bbox'])\n",
    "#convert to BGR to show image\n",
    "image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "image = draw_bboxes(image, annotation)\n",
    "\n",
    "# bounding box does not scale with image: Fix soon\n",
    "cv2.namedWindow('bruh', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('bruh', 800, 800)\n",
    "cv2.imshow('bruh', image)\n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml_work')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af1448973621cca8d0995b94d6d872e3dddfa331ed54f610a151f715a83fc53a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
